From a378db9bf289467104212fd7825a7400e57b4f0f Mon Sep 17 00:00:00 2001
From: aaa <aaa@111.com>
Date: Thu, 30 May 2024 21:00:19 +0800
Subject: [PATCH] yuv444 commit

---
 src/platform/common.h                         |  10 +
 src/platform/windows/display_vram.cpp         | 296 +++++++++++++-----
 src/video.cpp                                 |  88 ++++--
 src/video.h                                   |  14 +-
 src/video_colorspace.cpp                      |  10 +-
 .../linux/shaders/opengl/ConvertYUV.frag      |  31 ++
 .../directx/convert_vuya_planar_ps.hlsl       |   3 +
 .../convert_vuya_planar_ps_linear.hlsl        |   3 +
 ...t_vuya_planar_ps_perceptual_quantizer.hlsl |   3 +
 .../directx/convert_vuya_planar_vs.hlsl       |  10 +
 .../directx/convert_yuv444_planar_yuv_ps.hlsl |   3 +
 .../convert_yuv444_planar_yuv_ps_linear.hlsl  |   3 +
 ...44_planar_yuv_ps_perceptual_quantizer.hlsl |   3 +
 .../directx/convert_yuv444_planar_yuv_vs.hlsl |  10 +
 .../include/convert_vuya_planar_ps_base.hlsl  |  27 ++
 .../convert_yuv444_planar_yuv_ps_base.hlsl    |  27 ++
 16 files changed, 440 insertions(+), 101 deletions(-)
 create mode 100644 src_assets/linux/shaders/opengl/ConvertYUV.frag
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_linear.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_perceptual_quantizer.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_vuya_planar_vs.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_linear.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_perceptual_quantizer.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_vs.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/include/convert_vuya_planar_ps_base.hlsl
 create mode 100644 src_assets/windows/assets/shaders/directx/include/convert_yuv444_planar_yuv_ps_base.hlsl

diff --git a/src/platform/common.h b/src/platform/common.h
index 007f7ec..4e1a6c4 100644
--- a/src/platform/common.h
+++ b/src/platform/common.h
@@ -200,6 +200,11 @@ namespace platf {
     yuv420p10,
     nv12,
     p010,
+    yuv444p,
+    yuv444p10,
+    yuv444,
+    yuv444_10,
+    bgra,
     unknown
   };
 
@@ -214,6 +219,11 @@ namespace platf {
       _CONVERT(yuv420p10);
       _CONVERT(nv12);
       _CONVERT(p010);
+      _CONVERT(yuv444p);
+      _CONVERT(yuv444p10);
+      _CONVERT(yuv444);
+      _CONVERT(yuv444_10);
+      _CONVERT(bgra);
       _CONVERT(unknown);
     }
 #undef _CONVERT
diff --git a/src/platform/windows/display_vram.cpp b/src/platform/windows/display_vram.cpp
index 4aa1800..ff5f685 100644
--- a/src/platform/windows/display_vram.cpp
+++ b/src/platform/windows/display_vram.cpp
@@ -110,6 +110,14 @@ namespace platf::dxgi {
   blob_t convert_yuv420_planar_y_ps_linear_hlsl;
   blob_t convert_yuv420_planar_y_ps_perceptual_quantizer_hlsl;
   blob_t convert_yuv420_planar_y_vs_hlsl;
+  blob_t convert_yuv444_planar_yuv_ps_hlsl;
+  blob_t convert_yuv444_planar_yuv_ps_linear_hlsl;
+  blob_t convert_yuv444_planar_yuv_ps_perceptual_quantizer_hlsl;
+  blob_t convert_yuv444_planar_yuv_vs_hlsl;
+  blob_t convert_vuya_planar_ps_hlsl;
+  blob_t convert_vuya_planar_ps_linear_hlsl;
+  blob_t convert_vuya_planar_ps_perceptual_quantizer_hlsl;
+  blob_t convert_vuya_planar_vs_hlsl;
   blob_t cursor_ps_hlsl;
   blob_t cursor_ps_normalize_white_hlsl;
   blob_t cursor_vs_hlsl;
@@ -374,6 +382,9 @@ namespace platf::dxgi {
 
   class d3d_base_encode_device final {
   public:
+    int yuv444p10mask;
+    int bgramask;
+    int yuv444mask;
     int
     convert(platf::img_t &img_base) {
       // Garbage collect mapped capture images whose weak references have expired
@@ -402,18 +413,28 @@ namespace platf::dxgi {
           return -1;
         }
 
-        device_ctx->OMSetRenderTargets(1, &nv12_Y_rt, nullptr);
-        device_ctx->VSSetShader(scene_vs.get(), nullptr, 0);
-        device_ctx->PSSetShader(img.format == DXGI_FORMAT_R16G16B16A16_FLOAT ? convert_Y_fp16_ps.get() : convert_Y_ps.get(), nullptr, 0);
-        device_ctx->RSSetViewports(1, &outY_view);
-        device_ctx->PSSetShaderResources(0, 1, &img_ctx.encoder_input_res);
-        device_ctx->Draw(3, 0);
-
-        device_ctx->OMSetRenderTargets(1, &nv12_UV_rt, nullptr);
-        device_ctx->VSSetShader(convert_UV_vs.get(), nullptr, 0);
-        device_ctx->PSSetShader(img.format == DXGI_FORMAT_R16G16B16A16_FLOAT ? convert_UV_fp16_ps.get() : convert_UV_ps.get(), nullptr, 0);
-        device_ctx->RSSetViewports(1, &outUV_view);
-        device_ctx->Draw(3, 0);
+	if (yuv444p10mask == 1 || yuv444mask == 1) {
+	  device_ctx->OMSetRenderTargets(1, &yuv444_rt, nullptr);
+          device_ctx->VSSetShader(scene_vs.get(), nullptr, 0);
+          device_ctx->PSSetShader((img.format == DXGI_FORMAT_R16G16B16A16_FLOAT || img.format == DXGI_FORMAT_R10G10B10A2_UNORM) ? convert_YUV_fp16_ps.get() : convert_YUV_ps.get(), nullptr, 0);
+          device_ctx->RSSetViewports(1, &outYUV_view);
+          device_ctx->PSSetShaderResources(0, 1, &img_ctx.encoder_input_res);
+          device_ctx->Draw(3, 0);
+	}
+	else {
+          device_ctx->OMSetRenderTargets(1, &nv12_Y_rt, nullptr);
+          device_ctx->VSSetShader(scene_vs.get(), nullptr, 0);
+          device_ctx->PSSetShader(img.format == DXGI_FORMAT_R16G16B16A16_FLOAT ? convert_Y_fp16_ps.get() : convert_Y_ps.get(), nullptr, 0);
+          device_ctx->RSSetViewports(1, &outY_view);
+          device_ctx->PSSetShaderResources(0, 1, &img_ctx.encoder_input_res);
+          device_ctx->Draw(3, 0);
+
+          device_ctx->OMSetRenderTargets(1, &nv12_UV_rt, nullptr);
+          device_ctx->VSSetShader(convert_UV_vs.get(), nullptr, 0);
+          device_ctx->PSSetShader(img.format == DXGI_FORMAT_R16G16B16A16_FLOAT ? convert_UV_fp16_ps.get() : convert_UV_ps.get(), nullptr, 0);
+          device_ctx->RSSetViewports(1, &outUV_view);
+          device_ctx->Draw(3, 0);
+	}
 
         // Release encoder mutex to allow capture code to reuse this image
         img_ctx.encoder_mutex->ReleaseSync(0);
@@ -465,17 +486,22 @@ namespace platf::dxgi {
       auto offsetX = (out_width - out_width_f) / 2;
       auto offsetY = (out_height - out_height_f) / 2;
 
-      outY_view = D3D11_VIEWPORT { offsetX, offsetY, out_width_f, out_height_f, 0.0f, 1.0f };
-      outUV_view = D3D11_VIEWPORT { offsetX / 2, offsetY / 2, out_width_f / 2, out_height_f / 2, 0.0f, 1.0f };
+      if (yuv444p10mask == 1 || yuv444mask == 1) {
+	outYUV_view = D3D11_VIEWPORT { offsetX, offsetY, out_width_f, out_height_f, 0.0f, 1.0f };
+      }
+      else {
+        outY_view = D3D11_VIEWPORT { offsetX, offsetY, out_width_f, out_height_f, 0.0f, 1.0f };
+        outUV_view = D3D11_VIEWPORT { offsetX / 2, offsetY / 2, out_width_f / 2, out_height_f / 2, 0.0f, 1.0f };
 
-      float subsample_offset_in[16 / sizeof(float)] { 1.0f / (float) out_width_f, 1.0f / (float) out_height_f };  // aligned to 16-byte
-      subsample_offset = make_buffer(device.get(), subsample_offset_in);
+        float subsample_offset_in[16 / sizeof(float)] { 1.0f / (float) out_width_f, 1.0f / (float) out_height_f };  // aligned to 16-byte
+        subsample_offset = make_buffer(device.get(), subsample_offset_in);
 
-      if (!subsample_offset) {
-        BOOST_LOG(error) << "Failed to create subsample offset vertex constant buffer";
-        return -1;
+        if (!subsample_offset) {
+          BOOST_LOG(error) << "Failed to create subsample offset vertex constant buffer";
+          return -1;
+        }
+        device_ctx->VSSetConstantBuffers(0, 1, &subsample_offset);
       }
-      device_ctx->VSSetConstantBuffers(0, 1, &subsample_offset);
 
       {
         int32_t rotation_modifier = display->display_rotation == DXGI_MODE_ROTATION_UNSPECIFIED ? 0 : display->display_rotation - 1;
@@ -488,31 +514,55 @@ namespace platf::dxgi {
         device_ctx->VSSetConstantBuffers(1, 1, &rotation);
       }
 
-      D3D11_RENDER_TARGET_VIEW_DESC nv12_rt_desc {
-        format == DXGI_FORMAT_P010 ? DXGI_FORMAT_R16_UNORM : DXGI_FORMAT_R8_UNORM,
-        D3D11_RTV_DIMENSION_TEXTURE2D
-      };
+      if (yuv444p10mask == 1 || yuv444mask == 1) {
+	D3D11_RENDER_TARGET_VIEW_DESC yuv444_rt_desc {
+          format == DXGI_FORMAT_Y410 ? DXGI_FORMAT_R10G10B10A2_UNORM : DXGI_FORMAT_R8G8B8A8_UNORM,
+          D3D11_RTV_DIMENSION_TEXTURE2D
+        };
 
-      auto status = device->CreateRenderTargetView(output_texture.get(), &nv12_rt_desc, &nv12_Y_rt);
-      if (FAILED(status)) {
-        BOOST_LOG(error) << "Failed to create render target view [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
+        auto status = device->CreateRenderTargetView(output_texture.get(), &yuv444_rt_desc, &yuv444_rt);
+        if (FAILED(status)) {
+          BOOST_LOG(error) << "Failed to create render target view [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        // Clear the RTVs to ensure the aspect ratio padding is black
+	if (yuv444p10mask == 1) {
+	  const float xv30_black[]  = { 0.0f, 0.5f, 0.0f, 0.5f };
+	  device_ctx->ClearRenderTargetView(yuv444_rt.get(), xv30_black);
+	}
+	else {
+          const float vuyx_black[] = { 0.5f, 0.5f, 0.0f, 0.0f };
+	  device_ctx->ClearRenderTargetView(yuv444_rt.get(), vuyx_black);
+	}
       }
-
-      nv12_rt_desc.Format = (format == DXGI_FORMAT_P010) ? DXGI_FORMAT_R16G16_UNORM : DXGI_FORMAT_R8G8_UNORM;
-
-      status = device->CreateRenderTargetView(output_texture.get(), &nv12_rt_desc, &nv12_UV_rt);
-      if (FAILED(status)) {
-        BOOST_LOG(error) << "Failed to create render target view [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
+      else {
+        D3D11_RENDER_TARGET_VIEW_DESC nv12_rt_desc {
+          format == DXGI_FORMAT_P010 ? DXGI_FORMAT_R16_UNORM : DXGI_FORMAT_R8_UNORM,
+          D3D11_RTV_DIMENSION_TEXTURE2D
+        };
+  
+        auto status = device->CreateRenderTargetView(output_texture.get(), &nv12_rt_desc, &nv12_Y_rt);
+        if (FAILED(status)) {
+          BOOST_LOG(error) << "Failed to create render target view [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        nv12_rt_desc.Format = (format == DXGI_FORMAT_P010) ? DXGI_FORMAT_R16G16_UNORM : DXGI_FORMAT_R8G8_UNORM;
+  
+        status = device->CreateRenderTargetView(output_texture.get(), &nv12_rt_desc, &nv12_UV_rt);
+        if (FAILED(status)) {
+          BOOST_LOG(error) << "Failed to create render target view [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        // Clear the RTVs to ensure the aspect ratio padding is black
+        const float y_black[] = { 0.0f, 0.0f, 0.0f, 0.0f };
+        device_ctx->ClearRenderTargetView(nv12_Y_rt.get(), y_black);
+        const float uv_black[] = { 0.5f, 0.5f, 0.5f, 0.5f };
+        device_ctx->ClearRenderTargetView(nv12_UV_rt.get(), uv_black);
       }
 
-      // Clear the RTVs to ensure the aspect ratio padding is black
-      const float y_black[] = { 0.0f, 0.0f, 0.0f, 0.0f };
-      device_ctx->ClearRenderTargetView(nv12_Y_rt.get(), y_black);
-      const float uv_black[] = { 0.5f, 0.5f, 0.5f, 0.5f };
-      device_ctx->ClearRenderTargetView(nv12_UV_rt.get(), uv_black);
-
       return 0;
     }
 
@@ -556,62 +606,133 @@ namespace platf::dxgi {
         BOOST_LOG(warning) << "Failed to increase encoding GPU thread priority. Please run application as administrator for optimal performance.";
       }
 
-      format = (pix_fmt == pix_fmt_e::nv12 ? DXGI_FORMAT_NV12 : DXGI_FORMAT_P010);
-      status = device->CreateVertexShader(convert_yuv420_planar_y_vs_hlsl->GetBufferPointer(), convert_yuv420_planar_y_vs_hlsl->GetBufferSize(), nullptr, &scene_vs);
-      if (status) {
-        BOOST_LOG(error) << "Failed to create scene vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
-      }
-
-      status = device->CreateVertexShader(convert_yuv420_packed_uv_type0_vs_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_vs_hlsl->GetBufferSize(), nullptr, &convert_UV_vs);
-      if (status) {
-        BOOST_LOG(error) << "Failed to create convertUV vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
-      }
-
-      // If the display is in HDR and we're streaming HDR, we'll be converting scRGB to SMPTE 2084 PQ.
-      if (format == DXGI_FORMAT_P010 && display->is_hdr()) {
-        status = device->CreatePixelShader(convert_yuv420_planar_y_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_Y_fp16_ps);
+      yuv444p10mask = (pix_fmt == pix_fmt_e::yuv444_10) ? 1 : 0;
+      bgramask = (pix_fmt == pix_fmt_e::bgra) ? 1 : 0;
+      yuv444mask = (pix_fmt == pix_fmt_e::yuv444) ? 1 : 0;
+      if (yuv444p10mask == 1) {
+	format = DXGI_FORMAT_Y410;
+        status = device->CreateVertexShader(convert_yuv444_planar_yuv_vs_hlsl->GetBufferPointer(), convert_yuv444_planar_yuv_vs_hlsl->GetBufferSize(), nullptr, &scene_vs);
+        if (status) {
+          BOOST_LOG(error) << "Failed to create scene vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        // If the display is in HDR and we're streaming HDR, we'll be converting scRGB to SMPTE 2084 PQ.
+        if (format == DXGI_FORMAT_Y410 && display->is_hdr()) {
+          status = device->CreatePixelShader(convert_yuv444_planar_yuv_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_yuv444_planar_yuv_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_YUV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+        else {
+          // If the display is in Advanced Color mode, the desktop format will be scRGB FP16.
+          // scRGB uses linear gamma, so we must use our linear to sRGB conversion shaders.
+          status = device->CreatePixelShader(convert_yuv444_planar_yuv_ps_linear_hlsl->GetBufferPointer(), convert_yuv444_planar_yuv_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_YUV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+  
+        // These shaders consume standard 8-bit sRGB input
+        status = device->CreatePixelShader(convert_yuv444_planar_yuv_ps_hlsl->GetBufferPointer(), convert_yuv444_planar_yuv_ps_hlsl->GetBufferSize(), nullptr, &convert_YUV_ps);
         if (status) {
           BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
           return -1;
         }
-
-        status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_UV_fp16_ps);
+      }
+      else if (yuv444mask == 1) {
+	format = DXGI_FORMAT_AYUV;
+        status = device->CreateVertexShader(convert_vuya_planar_vs_hlsl->GetBufferPointer(), convert_vuya_planar_vs_hlsl->GetBufferSize(), nullptr, &scene_vs);
         if (status) {
-          BOOST_LOG(error) << "Failed to create convertUV pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+          BOOST_LOG(error) << "Failed to create scene vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        // If the display is in HDR and we're streaming HDR, we'll be converting scRGB to SMPTE 2084 PQ.
+        if (format == DXGI_FORMAT_Y410 && display->is_hdr()) {
+          status = device->CreatePixelShader(convert_vuya_planar_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_vuya_planar_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_YUV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+        else {
+          // If the display is in Advanced Color mode, the desktop format will be scRGB FP16.
+          // scRGB uses linear gamma, so we must use our linear to sRGB conversion shaders.
+          status = device->CreatePixelShader(convert_vuya_planar_ps_linear_hlsl->GetBufferPointer(), convert_vuya_planar_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_YUV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+  
+        // These shaders consume standard 8-bit sRGB input
+        status = device->CreatePixelShader(convert_vuya_planar_ps_hlsl->GetBufferPointer(), convert_vuya_planar_ps_hlsl->GetBufferSize(), nullptr, &convert_YUV_ps);
+        if (status) {
+          BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
           return -1;
         }
       }
       else {
-        // If the display is in Advanced Color mode, the desktop format will be scRGB FP16.
-        // scRGB uses linear gamma, so we must use our linear to sRGB conversion shaders.
-        status = device->CreatePixelShader(convert_yuv420_planar_y_ps_linear_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_Y_fp16_ps);
+        format = (pix_fmt == pix_fmt_e::nv12 ? DXGI_FORMAT_NV12 : DXGI_FORMAT_P010);
+        status = device->CreateVertexShader(convert_yuv420_planar_y_vs_hlsl->GetBufferPointer(), convert_yuv420_planar_y_vs_hlsl->GetBufferSize(), nullptr, &scene_vs);
+        if (status) {
+          BOOST_LOG(error) << "Failed to create scene vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        status = device->CreateVertexShader(convert_yuv420_packed_uv_type0_vs_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_vs_hlsl->GetBufferSize(), nullptr, &convert_UV_vs);
+        if (status) {
+          BOOST_LOG(error) << "Failed to create convertUV vertex shader [0x"sv << util::hex(status).to_string_view() << ']';
+          return -1;
+        }
+  
+        // If the display is in HDR and we're streaming HDR, we'll be converting scRGB to SMPTE 2084 PQ.
+        if (format == DXGI_FORMAT_P010 && display->is_hdr()) {
+          status = device->CreatePixelShader(convert_yuv420_planar_y_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_Y_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+  
+          status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_perceptual_quantizer_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_perceptual_quantizer_hlsl->GetBufferSize(), nullptr, &convert_UV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertUV pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+        else {
+          // If the display is in Advanced Color mode, the desktop format will be scRGB FP16.
+          // scRGB uses linear gamma, so we must use our linear to sRGB conversion shaders.
+          status = device->CreatePixelShader(convert_yuv420_planar_y_ps_linear_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_Y_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+  
+          status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_linear_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_UV_fp16_ps);
+          if (status) {
+            BOOST_LOG(error) << "Failed to create convertUV pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
+            return -1;
+          }
+        }
+  
+        // These shaders consume standard 8-bit sRGB input
+        status = device->CreatePixelShader(convert_yuv420_planar_y_ps_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_hlsl->GetBufferSize(), nullptr, &convert_Y_ps);
         if (status) {
           BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
           return -1;
         }
-
-        status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_linear_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_linear_hlsl->GetBufferSize(), nullptr, &convert_UV_fp16_ps);
+  
+        status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_hlsl->GetBufferSize(), nullptr, &convert_UV_ps);
         if (status) {
           BOOST_LOG(error) << "Failed to create convertUV pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
           return -1;
         }
       }
 
-      // These shaders consume standard 8-bit sRGB input
-      status = device->CreatePixelShader(convert_yuv420_planar_y_ps_hlsl->GetBufferPointer(), convert_yuv420_planar_y_ps_hlsl->GetBufferSize(), nullptr, &convert_Y_ps);
-      if (status) {
-        BOOST_LOG(error) << "Failed to create convertY pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
-      }
-
-      status = device->CreatePixelShader(convert_yuv420_packed_uv_type0_ps_hlsl->GetBufferPointer(), convert_yuv420_packed_uv_type0_ps_hlsl->GetBufferSize(), nullptr, &convert_UV_ps);
-      if (status) {
-        BOOST_LOG(error) << "Failed to create convertUV pixel shader [0x"sv << util::hex(status).to_string_view() << ']';
-        return -1;
-      }
-
       auto default_color_vectors = ::video::color_vectors_from_colorspace(::video::colorspace_e::rec601, false);
       if (!default_color_vectors) {
         BOOST_LOG(error) << "Missing color vectors for Rec. 601"sv;
@@ -735,6 +856,7 @@ namespace platf::dxgi {
 
     render_target_t nv12_Y_rt;
     render_target_t nv12_UV_rt;
+    render_target_t yuv444_rt;
 
     // d3d_img_t::id -> encoder_img_ctx_t
     // These store the encoder textures for each img_t that passes through
@@ -749,10 +871,13 @@ namespace platf::dxgi {
     ps_t convert_UV_fp16_ps;
     ps_t convert_Y_ps;
     ps_t convert_Y_fp16_ps;
+    ps_t convert_YUV_ps;
+    ps_t convert_YUV_fp16_ps;
     vs_t scene_vs;
 
     D3D11_VIEWPORT outY_view;
     D3D11_VIEWPORT outUV_view;
+    D3D11_VIEWPORT outYUV_view;
 
     DXGI_FORMAT format;
 
@@ -1367,7 +1492,7 @@ namespace platf::dxgi {
       device_ctx->VSSetConstantBuffers(2, 1, &rotation);
     }
 
-    if (config.dynamicRange && is_hdr()) {
+    if ((config.dynamicRange == 1 || config.dynamicRange >= 3) && is_hdr()) {
       // This shader will normalize scRGB white levels to a user-defined white level
       status = device->CreatePixelShader(cursor_ps_normalize_white_hlsl->GetBufferPointer(), cursor_ps_normalize_white_hlsl->GetBufferSize(), nullptr, &cursor_ps);
       if (status) {
@@ -1529,6 +1654,7 @@ namespace platf::dxgi {
       // We include the 8-bit modes too for when the display is in SDR mode,
       // while the client stream is HDR-capable. These UNORM formats can
       // use our normal pixel shaders that expect sRGB input.
+      DXGI_FORMAT_R10G10B10A2_UNORM,
       DXGI_FORMAT_B8G8R8A8_UNORM,
       DXGI_FORMAT_B8G8R8X8_UNORM,
       DXGI_FORMAT_R8G8B8A8_UNORM,
@@ -1576,7 +1702,7 @@ namespace platf::dxgi {
               BOOST_LOG(warning) << "If your AMD GPU supports AV1 encoding, update your graphics drivers!"sv;
               return false;
             }
-            else if (config.dynamicRange && version < AMF_MAKE_FULL_VERSION(1, 4, 23, 0)) {
+            else if ((config.dynamicRange == 1 || config.dynamicRange >= 3) && version < AMF_MAKE_FULL_VERSION(1, 4, 23, 0)) {
               // Older versions of the AMD AMF runtime can crash when fed P010 surfaces.
               // Fail if AMF version is below 1.4.23 where HEVC Main10 encoding was introduced.
               // AMF 1.4.23 corresponds to driver version 21.12.1 (21.40.11.03) or newer.
@@ -1622,7 +1748,7 @@ namespace platf::dxgi {
 
   std::unique_ptr<avcodec_encode_device_t>
   display_vram_t::make_avcodec_encode_device(pix_fmt_e pix_fmt) {
-    if (pix_fmt != platf::pix_fmt_e::nv12 && pix_fmt != platf::pix_fmt_e::p010) {
+    if (pix_fmt != platf::pix_fmt_e::nv12 && pix_fmt != platf::pix_fmt_e::p010 && pix_fmt != platf::pix_fmt_e::bgra && pix_fmt != platf::pix_fmt_e::yuv444 && pix_fmt != platf::pix_fmt_e::yuv444_10) {
       BOOST_LOG(error) << "display_vram_t doesn't support pixel format ["sv << from_pix_fmt(pix_fmt) << ']';
 
       return nullptr;
@@ -1665,6 +1791,14 @@ namespace platf::dxgi {
     compile_pixel_shader_helper(convert_yuv420_planar_y_ps_linear);
     compile_pixel_shader_helper(convert_yuv420_planar_y_ps_perceptual_quantizer);
     compile_vertex_shader_helper(convert_yuv420_planar_y_vs);
+    compile_pixel_shader_helper(convert_yuv444_planar_yuv_ps);
+    compile_pixel_shader_helper(convert_yuv444_planar_yuv_ps_linear);
+    compile_pixel_shader_helper(convert_yuv444_planar_yuv_ps_perceptual_quantizer);
+    compile_vertex_shader_helper(convert_yuv444_planar_yuv_vs);
+    compile_pixel_shader_helper(convert_vuya_planar_ps);
+    compile_pixel_shader_helper(convert_vuya_planar_ps_linear);
+    compile_pixel_shader_helper(convert_vuya_planar_ps_perceptual_quantizer);
+    compile_vertex_shader_helper(convert_vuya_planar_vs);
     compile_pixel_shader_helper(cursor_ps);
     compile_pixel_shader_helper(cursor_ps_normalize_white);
     compile_vertex_shader_helper(cursor_vs);
diff --git a/src/video.cpp b/src/video.cpp
index 394e7d4..7eb1404 100644
--- a/src/video.cpp
+++ b/src/video.cpp
@@ -72,14 +72,30 @@ namespace video {
       baseline = 66,
       main = 77,
       high = 100,
+      high444 = 244,
     };
 
     enum class profile_hevc_e : int {
       main = 1,
       main_10 = 2,
+      rext = 4,
     };
   }  // namespace qsv
+  namespace swp {
 
+    enum class profile_h264_e : int {
+      baseline = 66,
+      main = 77,
+      high = 100,
+      high444 = 244,
+    };
+
+    enum class profile_hevc_e : int {
+      main = 1,
+      main_10 = 2,
+      rext = 4,
+    };
+  }  // namespace swp
   util::Either<avcodec_buffer_t, int>
   dxgi_init_avcodec_hardware_input_buffer(platf::avcodec_encode_device_t *);
   util::Either<avcodec_buffer_t, int>
@@ -447,7 +463,8 @@ namespace video {
     "nvenc"sv,
     std::make_unique<encoder_platform_formats_nvenc>(
       platf::mem_type_e::dxgi,
-      platf::pix_fmt_e::nv12, platf::pix_fmt_e::p010),
+      platf::pix_fmt_e::nv12, platf::pix_fmt_e::p010,
+      platf::pix_fmt_e::unknown, platf::pix_fmt_e::unknown),
     {
       // Common options
       {},
@@ -498,6 +515,7 @@ namespace video {
       AV_PIX_FMT_CUDA,
   #endif
       AV_PIX_FMT_NV12, AV_PIX_FMT_P010,
+      AV_PIX_FMT_NONE,AV_PIX_FMT_NONE,
   #ifdef _WIN32
       dxgi_init_avcodec_hardware_input_buffer
   #else
@@ -581,6 +599,7 @@ namespace video {
       AV_HWDEVICE_TYPE_D3D11VA, AV_HWDEVICE_TYPE_QSV,
       AV_PIX_FMT_QSV,
       AV_PIX_FMT_NV12, AV_PIX_FMT_P010,
+      AV_PIX_FMT_VUYX, AV_PIX_FMT_XV30,
       dxgi_init_avcodec_hardware_input_buffer),
     {
       // Common options
@@ -662,6 +681,7 @@ namespace video {
       AV_HWDEVICE_TYPE_D3D11VA, AV_HWDEVICE_TYPE_NONE,
       AV_PIX_FMT_D3D11,
       AV_PIX_FMT_NV12, AV_PIX_FMT_P010,
+      AV_PIX_FMT_VUYX, AV_PIX_FMT_XV30,
       dxgi_init_avcodec_hardware_input_buffer),
     {
       // Common options
@@ -737,6 +757,7 @@ namespace video {
       AV_HWDEVICE_TYPE_NONE, AV_HWDEVICE_TYPE_NONE,
       AV_PIX_FMT_NONE,
       AV_PIX_FMT_YUV420P, AV_PIX_FMT_YUV420P10,
+      AV_PIX_FMT_YUV444P, AV_PIX_FMT_YUV444P10,
       nullptr),
     {
       // libsvtav1 takes different presets than libx264/libx265.
@@ -802,6 +823,7 @@ namespace video {
       AV_HWDEVICE_TYPE_VAAPI, AV_HWDEVICE_TYPE_NONE,
       AV_PIX_FMT_VAAPI,
       AV_PIX_FMT_NV12, AV_PIX_FMT_P010,
+      AV_PIX_FMT_NONE,AV_PIX_FMT_NONE,
       vaapi_init_avcodec_hardware_input_buffer),
     {
       // Common options
@@ -870,6 +892,7 @@ namespace video {
       AV_HWDEVICE_TYPE_VIDEOTOOLBOX, AV_HWDEVICE_TYPE_NONE,
       AV_PIX_FMT_VIDEOTOOLBOX,
       AV_PIX_FMT_NV12, AV_PIX_FMT_P010,
+      AV_PIX_FMT_NONE,AV_PIX_FMT_NONE,
       vt_init_avcodec_hardware_input_buffer),
     {
       // Common options
@@ -909,9 +932,7 @@ namespace video {
       },
       {},  // SDR-specific options
       {},  // HDR-specific options
-      {
-        { "flags"s, "-low_delay" },
-      },  // Fallback options
+      {},  // Fallback options
       std::nullopt,
       "h264_videotoolbox"s,
     },
@@ -1296,10 +1317,6 @@ namespace video {
         return ret;
       }
 
-      if (av_packet->flags & AV_PKT_FLAG_KEY) {
-        BOOST_LOG(debug) << "Frame "sv << frame_nr << ": IDR Keyframe (AV_FRAME_FLAG_KEY)"sv;
-      }
-
       if ((frame->flags & AV_FRAME_FLAG_KEY) && !(av_packet->flags & AV_PKT_FLAG_KEY)) {
         BOOST_LOG(error) << "Encoder did not produce IDR frame when requested!"sv;
       }
@@ -1390,7 +1407,10 @@ namespace video {
       return nullptr;
     }
 
-    if (config.dynamicRange && !video_format[encoder_t::DYNAMIC_RANGE]) {
+    bool isHdrRequest = (config.dynamicRange == 1 || config.dynamicRange == 3) ? true : false;
+    bool isYuv444Request = (config.dynamicRange == 2 || config.dynamicRange == 3) ? true : false;
+
+    if (isHdrRequest && !video_format[encoder_t::DYNAMIC_RANGE]) {
       BOOST_LOG(error) << video_format.name << ": dynamic range not supported"sv;
       return nullptr;
     }
@@ -1403,7 +1423,7 @@ namespace video {
     }
 
     auto colorspace = encode_device->colorspace;
-    auto sw_fmt = (colorspace.bit_depth == 10) ? platform_formats->avcodec_pix_fmt_10bit : platform_formats->avcodec_pix_fmt_8bit;
+    auto sw_fmt = (colorspace.bit_depth == 10) ? (isYuv444Request ? platform_formats->avcodec_pix_fmt_10bit_444 : platform_formats->avcodec_pix_fmt_10bit) : (isYuv444Request ? platform_formats->avcodec_pix_fmt_8bit_444 : platform_formats->avcodec_pix_fmt_8bit);
 
     // Allow up to 1 retry to apply the set of fallback options.
     //
@@ -1420,11 +1440,11 @@ namespace video {
 
       switch (config.videoFormat) {
         case 0:
-          ctx->profile = FF_PROFILE_H264_HIGH;
+          ctx->profile = isYuv444Request ? FF_PROFILE_H264_HIGH_444_PREDICTIVE : FF_PROFILE_H264_HIGH;
           break;
 
         case 1:
-          ctx->profile = config.dynamicRange ? FF_PROFILE_HEVC_MAIN_10 : FF_PROFILE_HEVC_MAIN;
+          ctx->profile = isYuv444Request ? FF_PROFILE_HEVC_REXT : (isHdrRequest ? FF_PROFILE_HEVC_MAIN_10 : FF_PROFILE_HEVC_MAIN);
           break;
 
         case 2:
@@ -1453,10 +1473,7 @@ namespace video {
         }
       }
 
-      // We forcefully reset the flags to avoid clash on reuse of AVCodecContext
-      ctx->flags = 0;
-      ctx->flags |= AV_CODEC_FLAG_CLOSED_GOP | AV_CODEC_FLAG_LOW_DELAY;
-
+      ctx->flags |= (AV_CODEC_FLAG_CLOSED_GOP | AV_CODEC_FLAG_LOW_DELAY);
       ctx->flags2 |= AV_CODEC_FLAG2_FAST;
 
       auto avcodec_colorspace = avcodec_colorspace_from_sunshine_colorspace(colorspace);
@@ -1557,7 +1574,7 @@ namespace video {
       for (auto &option : video_format.common_options) {
         handle_option(option);
       }
-      for (auto &option : (config.dynamicRange ? video_format.hdr_options : video_format.sdr_options)) {
+      for (auto &option : (isHdrRequest ? video_format.hdr_options : video_format.sdr_options)) {
         handle_option(option);
       }
       if (retries > 0) {
@@ -1609,6 +1626,31 @@ namespace video {
         BOOST_LOG(error) << "Couldn't set video quality: encoder "sv << encoder.name << " doesn't support qp"sv;
         return nullptr;
       }
+      // my defined options
+      if (isYuv444Request) {
+        encoder_t::option_t libx264_444_option = { "profile"s, "high444"s };
+        encoder_t::option_t hevc_444_option = { "profile"s, (int) swp::profile_hevc_e::rext };  // qsv only can encode vuyx when using hevc
+        encoder_t::option_t sw_crf = { "crf"s, 0 };
+	encoder_t::option_t libx265_444_option = { "profile"s, "main444-8"s };
+        switch (config.videoFormat) {
+          case 0:
+            //h264
+            break;
+          case 1:
+  	  // for qsv hevc_444
+	    if (hardware)
+              handle_option(hevc_444_option);
+	    else
+	      handle_option(libx265_444_option);
+            break;
+          case 2:
+            // AV1 
+            break;
+        }
+        if (!hardware) {
+  	handle_option(sw_crf);
+        }
+      }
 
       if (auto status = avcodec_open2(ctx.get(), codec, &options)) {
         char err_str[AV_ERROR_MAX_STRING_SIZE] { 0 };
@@ -1870,7 +1912,7 @@ namespace video {
     std::unique_ptr<platf::encode_device_t> result;
 
     auto colorspace = colorspace_from_client_config(config, disp.is_hdr());
-    auto pix_fmt = (colorspace.bit_depth == 10) ? encoder.platform_formats->pix_fmt_10bit : encoder.platform_formats->pix_fmt_8bit;
+    auto pix_fmt = (colorspace.bit_depth == 10) ? ((config.dynamicRange == 2 || config.dynamicRange == 3) ? encoder.platform_formats->pix_fmt_10bit_444 : encoder.platform_formats->pix_fmt_10bit) : ((config.dynamicRange == 2 || config.dynamicRange == 3) ? encoder.platform_formats->pix_fmt_8bit_444 : encoder.platform_formats->pix_fmt_8bit);
 
     if (dynamic_cast<const encoder_platform_formats_avcodec *>(encoder.platform_formats.get())) {
       result = disp.make_avcodec_encode_device(pix_fmt);
@@ -2803,6 +2845,16 @@ namespace video {
         return platf::pix_fmt_e::nv12;
       case AV_PIX_FMT_P010:
         return platf::pix_fmt_e::p010;
+      case AV_PIX_FMT_YUV444P10:
+        return platf::pix_fmt_e::yuv444p10;
+      case AV_PIX_FMT_YUV444P:
+        return platf::pix_fmt_e::yuv444p;
+      case AV_PIX_FMT_XV30:
+        return platf::pix_fmt_e::yuv444_10;
+      case AV_PIX_FMT_VUYX:
+        return platf::pix_fmt_e::yuv444;
+      case AV_PIX_FMT_BGRA:
+        return platf::pix_fmt_e::bgra;
       default:
         return platf::pix_fmt_e::unknown;
     }
diff --git a/src/video.h b/src/video.h
index ba80474..6b3117f 100644
--- a/src/video.h
+++ b/src/video.h
@@ -39,6 +39,7 @@ namespace video {
     virtual ~encoder_platform_formats_t() = default;
     platf::mem_type_e dev_type;
     platf::pix_fmt_e pix_fmt_8bit, pix_fmt_10bit;
+    platf::pix_fmt_e pix_fmt_8bit_444, pix_fmt_10bit_444;
   };
 
   struct encoder_platform_formats_avcodec: encoder_platform_formats_t {
@@ -50,21 +51,28 @@ namespace video {
       const AVPixelFormat &avcodec_dev_pix_fmt,
       const AVPixelFormat &avcodec_pix_fmt_8bit,
       const AVPixelFormat &avcodec_pix_fmt_10bit,
+      const AVPixelFormat &avcodec_pix_fmt_8bit_444,
+      const AVPixelFormat &avcodec_pix_fmt_10bit_444,
       const init_buffer_function_t &init_avcodec_hardware_input_buffer_function):
         avcodec_base_dev_type { avcodec_base_dev_type },
         avcodec_derived_dev_type { avcodec_derived_dev_type },
         avcodec_dev_pix_fmt { avcodec_dev_pix_fmt },
         avcodec_pix_fmt_8bit { avcodec_pix_fmt_8bit },
         avcodec_pix_fmt_10bit { avcodec_pix_fmt_10bit },
+        avcodec_pix_fmt_8bit_444 { avcodec_pix_fmt_8bit_444 },
+        avcodec_pix_fmt_10bit_444 { avcodec_pix_fmt_10bit_444 },
         init_avcodec_hardware_input_buffer { init_avcodec_hardware_input_buffer_function } {
       dev_type = map_base_dev_type(avcodec_base_dev_type);
       pix_fmt_8bit = map_pix_fmt(avcodec_pix_fmt_8bit);
       pix_fmt_10bit = map_pix_fmt(avcodec_pix_fmt_10bit);
+      pix_fmt_8bit_444 = map_pix_fmt(avcodec_pix_fmt_8bit_444);
+      pix_fmt_10bit_444 = map_pix_fmt(avcodec_pix_fmt_10bit_444);
     }
 
     AVHWDeviceType avcodec_base_dev_type, avcodec_derived_dev_type;
     AVPixelFormat avcodec_dev_pix_fmt;
     AVPixelFormat avcodec_pix_fmt_8bit, avcodec_pix_fmt_10bit;
+    AVPixelFormat avcodec_pix_fmt_8bit_444, avcodec_pix_fmt_10bit_444;
 
     init_buffer_function_t init_avcodec_hardware_input_buffer;
   };
@@ -73,10 +81,14 @@ namespace video {
     encoder_platform_formats_nvenc(
       const platf::mem_type_e &dev_type,
       const platf::pix_fmt_e &pix_fmt_8bit,
-      const platf::pix_fmt_e &pix_fmt_10bit) {
+      const platf::pix_fmt_e &pix_fmt_10bit,
+      const platf::pix_fmt_e &pix_fmt_8bit_444,
+      const platf::pix_fmt_e &pix_fmt_10bit_444) {
       encoder_platform_formats_t::dev_type = dev_type;
       encoder_platform_formats_t::pix_fmt_8bit = pix_fmt_8bit;
       encoder_platform_formats_t::pix_fmt_10bit = pix_fmt_10bit;
+      encoder_platform_formats_t::pix_fmt_8bit_444 = pix_fmt_8bit_444;
+      encoder_platform_formats_t::pix_fmt_10bit_444 = pix_fmt_10bit_444;
     }
   };
 
diff --git a/src/video_colorspace.cpp b/src/video_colorspace.cpp
index 4f5955e..9e631fb 100644
--- a/src/video_colorspace.cpp
+++ b/src/video_colorspace.cpp
@@ -20,10 +20,16 @@ namespace video {
 
     /* See video::config_t declaration for details */
 
-    if (config.dynamicRange > 0 && hdr_display) {
+    if ((config.dynamicRange == 1 || config.dynamicRange >= 3) && hdr_display) {
       // Rec. 2020 with ST 2084 perceptual quantizer
       colorspace.colorspace = colorspace_e::bt2020;
     }
+    else if (config.dynamicRange == 2) {
+      colorspace.colorspace = colorspace_e::rec709;
+      colorspace.bit_depth = 8;
+      colorspace.full_range = 1;
+      return colorspace;
+    }
     else {
       switch (config.encoderCscMode >> 1) {
         case 0:
@@ -52,10 +58,12 @@ namespace video {
 
     switch (config.dynamicRange) {
       case 0:
+      case 2:
         colorspace.bit_depth = 8;
         break;
 
       case 1:
+      case 3:
         colorspace.bit_depth = 10;
         break;
 
diff --git a/src_assets/linux/shaders/opengl/ConvertYUV.frag b/src_assets/linux/shaders/opengl/ConvertYUV.frag
new file mode 100644
index 0000000..3d7e9a8
--- /dev/null
+++ b/src_assets/linux/shaders/opengl/ConvertYUV.frag
@@ -0,0 +1,31 @@
+#version 300 es
+
+#ifdef GL_ES
+precision lowp float;
+#endif
+
+uniform sampler2D image;
+
+layout(shared) uniform ColorMatrix {
+  vec4 color_vec_y;
+  vec4 color_vec_u;
+  vec4 color_vec_v;
+  vec2 range_y;
+  vec2 range_uv;
+};
+
+in vec2 tex;
+layout(location = 0) out vec3 color;
+
+void main()
+{
+	vec3 rgb = texture(image, tex).rgb;
+	float y = dot(color_vec_y.xyz, rgb);
+	float u = dot(color_vec_u.xyz, rgb) + color_vec_u.w;
+	float v = dot(color_vec_v.xyz, rgb) + color_vec_v.w;
+
+	y = y * range_y.x + range_y.y;
+	u = u * range_uv.x + range_uv.y;
+	v = v * range_uv.x + range_uv.y;
+	color = vec3(y, u, v);
+}
\ No newline at end of file
diff --git a/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps.hlsl b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps.hlsl
new file mode 100644
index 0000000..304108d
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_base.hlsl"
+
+#include "include/convert_vuya_planar_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_linear.hlsl b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_linear.hlsl
new file mode 100644
index 0000000..82a0160
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_linear.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_linear_base.hlsl"
+
+#include "include/convert_vuya_planar_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_perceptual_quantizer.hlsl b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_perceptual_quantizer.hlsl
new file mode 100644
index 0000000..eb8a019
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_ps_perceptual_quantizer.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_perceptual_quantizer_base.hlsl"
+
+#include "include/convert_vuya_planar_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_vuya_planar_vs.hlsl b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_vs.hlsl
new file mode 100644
index 0000000..33e4814
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_vuya_planar_vs.hlsl
@@ -0,0 +1,10 @@
+cbuffer rotate_texture_steps_cbuffer : register(b1) {
+    int rotate_texture_steps;
+};
+
+#include "include/base_vs.hlsl"
+
+vertex_t main_vs(uint vertex_id : SV_VertexID)
+{
+    return generate_fullscreen_triangle_vertex(vertex_id, rotate_texture_steps);
+}
diff --git a/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps.hlsl b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps.hlsl
new file mode 100644
index 0000000..f6323ce
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_base.hlsl"
+
+#include "include/convert_yuv444_planar_yuv_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_linear.hlsl b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_linear.hlsl
new file mode 100644
index 0000000..e2dd48f
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_linear.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_linear_base.hlsl"
+
+#include "include/convert_yuv444_planar_yuv_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_perceptual_quantizer.hlsl b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_perceptual_quantizer.hlsl
new file mode 100644
index 0000000..32fc8d8
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_ps_perceptual_quantizer.hlsl
@@ -0,0 +1,3 @@
+#include "include/convert_perceptual_quantizer_base.hlsl"
+
+#include "include/convert_yuv444_planar_yuv_ps_base.hlsl"
diff --git a/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_vs.hlsl b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_vs.hlsl
new file mode 100644
index 0000000..33e4814
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/convert_yuv444_planar_yuv_vs.hlsl
@@ -0,0 +1,10 @@
+cbuffer rotate_texture_steps_cbuffer : register(b1) {
+    int rotate_texture_steps;
+};
+
+#include "include/base_vs.hlsl"
+
+vertex_t main_vs(uint vertex_id : SV_VertexID)
+{
+    return generate_fullscreen_triangle_vertex(vertex_id, rotate_texture_steps);
+}
diff --git a/src_assets/windows/assets/shaders/directx/include/convert_vuya_planar_ps_base.hlsl b/src_assets/windows/assets/shaders/directx/include/convert_vuya_planar_ps_base.hlsl
new file mode 100644
index 0000000..c45952f
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/include/convert_vuya_planar_ps_base.hlsl
@@ -0,0 +1,27 @@
+Texture2D image : register(t0);
+SamplerState def_sampler : register(s0);
+
+cbuffer color_matrix_cbuffer : register(b0) {
+    float4 color_vec_y;
+    float4 color_vec_u;
+    float4 color_vec_v;
+    float2 range_y;
+    float2 range_uv;
+};
+
+#include "include/base_vs_types.hlsl"
+
+float4 main_ps(vertex_t input) : SV_Target
+{
+    float3 rgb = CONVERT_FUNCTION(image.Sample(def_sampler, input.tex_coord, 0).rgb);
+
+    float y = dot(color_vec_y.xyz, rgb) + color_vec_y.w;
+    float u = dot(color_vec_u.xyz, rgb) + color_vec_u.w;
+    float v = dot(color_vec_v.xyz, rgb) + color_vec_v.w;
+
+    y = y * range_y.x + range_y.y;
+    u = u * range_uv.x + range_uv.y;
+    v = v * range_uv.x + range_uv.y;
+
+    return float4(v, u, y, 1.0f);
+}
diff --git a/src_assets/windows/assets/shaders/directx/include/convert_yuv444_planar_yuv_ps_base.hlsl b/src_assets/windows/assets/shaders/directx/include/convert_yuv444_planar_yuv_ps_base.hlsl
new file mode 100644
index 0000000..265360d
--- /dev/null
+++ b/src_assets/windows/assets/shaders/directx/include/convert_yuv444_planar_yuv_ps_base.hlsl
@@ -0,0 +1,27 @@
+Texture2D image : register(t0);
+SamplerState def_sampler : register(s0);
+
+cbuffer color_matrix_cbuffer : register(b0) {
+    float4 color_vec_y;
+    float4 color_vec_u;
+    float4 color_vec_v;
+    float2 range_y;
+    float2 range_uv;
+};
+
+#include "include/base_vs_types.hlsl"
+
+float3 main_ps(vertex_t input) : SV_Target
+{
+    float3 rgb = CONVERT_FUNCTION(image.Sample(def_sampler, input.tex_coord, 0).rgb);
+
+    float y = dot(color_vec_y.xyz, rgb) + color_vec_y.w;
+    float u = dot(color_vec_u.xyz, rgb) + color_vec_u.w;
+    float v = dot(color_vec_v.xyz, rgb) + color_vec_v.w;
+
+    y = y * range_y.x + range_y.y;
+    u = u * range_uv.x + range_uv.y;
+    v = v * range_uv.x + range_uv.y;
+
+    return float3(u, y, v);
+}
-- 
2.45.1

